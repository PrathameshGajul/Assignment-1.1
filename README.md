Q1. Various sources of Big Data
Ans: Big Data has various sources such as:
     1)Sensor Data - car sensors,road cameras,medical devices etc.
     2)Archieves - scanned documents,statements,insurance forms etc.
     3)Documents - pdfs,email,ppt etc.
     4)Machine Log Data - event logs,application logs,process logs etc.
     5)Data Storage - SQL,Hadoop,file systems etc.
     6)Public Web - traffic,weather etc.
     7)Social Media - facebook,twitter etc.
     8)Business Apps - Project management,automation,marketing etc.
     9)Media - images,audio,video etc.
     
Q2. 3 V's of Big Data
Ans: 1)Volume - It specifies the amount of data generated.
     2)Velocity - It specifies the rate at which the data is generated.
     3)Vareity - It specifies the different types of data generated.
     
Q3. Horizontal Scaling and Vertical Scaling
Ans: Horizontal Scaling:
     1)Horizontal scaling means that you scale by adding more machines into your pool of resources.
     2)In a database world horizontal-scaling is often based on partitioning of the data i.e. each node contains only part of the data.
     3)With horizontal-scaling it is often easier to scale dynamically by adding more machines into the existing pool.
     4)A good example for horizontal scaling is Cassandra , MongoDB.
     
     Vertical Scaling:
     1)Vertical scaling means that you scale by adding more power (CPU, RAM) to an existing machine.
     2)In vertical-scaling the data resides on a single node and scaling is done through multi-core.
     3)Vertical-scaling is often limited to the capacity of a single machine, scaling beyond that capacity often involves downtime and comes with an upper limit.
     4)A good example for vertical scaling is MySQL - Amazon RDS.
     
Q4. Need and Working of Hadoop
Ans: Need of Hadoop:
     1)Stage structured data - Use Hadoop as a data staging platform for your data warehouse.
     2)Process structured data - Use Hadoop to update data in your data warehouse and/or operational systems.
     3)Archive all data - Use Hadoop to archive all your data on-premises or in the cloud.
     4)Process any data - Use Hadoop to take advantage of data that’s currently unavailable in your enterprise data warehouse ecosystem.
     5)Access any data - Use Hadoop to extend your data warehouse and keep it at the center of your organization’s data universe.
     6)Access any data -Use Hadoop as the landing platform for all data and exploit the strengths of both the data warehouse and Hadoop.

     Working of Hadoop:
     1)Hadoop is a framework developed in java for handling big data.
     2)It uses HDFS (Hadoop Distributed File System) for storage.
     3)Hadoop uses a programming model called MapReduce for automated distributed computing.
     4)There are various other components like Hive,Hbase,Pig etc.
